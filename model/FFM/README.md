# FFM Model
### 原文PDF：[《Field-aware Factorization Machines for CTR Prediction》](FFM.pdf)
## 解决了什么问题？
FFM模型就是对FM模型的改进，FM模型虽然在特征交叉和复杂度上都表现优异，
但是在 FM 中，所有特征`共享同一个隐向量`，导致不同字段间的交互效果被统一处理，
无法区分特征属于不同字段时的交互差异。
## 如何解决？
FFM模型通过为每个特征在不同字段下引入不同的隐向量来解决这个问题。 

举个例子：性别特征在和年龄交互，以及和品牌交互时使用的hidden vector
应该是不一样的，FFM会为每个特征在其对应字段下分配不同的隐向量，这样可以让模型更好地学习到特征之间的关系。

field的定义需要人工实现，一般来讲在工业上都会为每个feature都分配一个field使其一一对应。

和 [FM](https://github.com/HaochengY/RecommendSystem/tree/main/models/FM) 一样，Pytorch中训练 `nn.Embedding()`的过程就是
学习隐向量的过程。

## 效果如何？
FFM 在当年的多项CTR预估比赛中夺魁，在不同的数据集上比较结果

| Data set                | LR      | Poly2    | FM       | FFM      |
|-------------------------|---------|----------|----------|----------|
| KDD2010-bridge           | 0.27947 | 0.2622   | 0.26372  | **`0.25639`**  |
| KDD2012                 | 0.15069 | 0.15099  | 0.15004  | **`0.14906`**  |
| phishing                | 0.14211 | 0.11512  | **`0.09229`**  | 0.1065   |
| adult                   | 0.3097  | 0.30655  | 0.30763  | **`0.30565`**  |
| cod-rna (dummy fields)   | 0.13829 | 0.12874  | **`0.12580`**  | 0.12914  |
| cod-rna (discretization) | 0.16455 | 0.17576  | 0.16570  | **`0.14993`**  |
| ijcnn (dummy fields)     | 0.20093 | 0.08981  | 0.07087  | **`0.0692`**   |
| ijcnn (discretization)   | 0.21588 | 0.24578  | 0.20223  | **`0.18608`**  |

但是需要注意，FM的本意是减少时间复杂度，可FFM的加入给时间复杂度比MF还高，但是FFM在牺牲了训练速度后，模型效果显著提升。

具体而言：

| 模型名称 | 复杂度      | 
|-------|--------------|
| FM    | $O(nk)$ | 
| FFM     |  $O(nmk)$ ， 当为每个特征都分配一个域的时候，复杂度为 $O(n^2k)$   | 


## FM模型与FFM模型的比较

1. 结构上上文已经表示很清楚，不同的特征在交互时应该使用不同的向量，从而`更精细地表达`交互关系。
2. 模型复杂度上FM是$O(nk)$，FFM是$O(nmk)$
3. FM更加适用于特征间交互不多，或者没有明显的域区分的特征；而FFM则恰恰相反。然而，从多数实验上来讲即使前者的情况出现，使用FFM也很少会带来负增益，`FM可以认为是FFM的一种特例情况`，因此在时间开销和计算资源允许下，FFM效果更好。


## 超参数调优结果

5%采样：

|         GAUC        |$\gamma = 0.1$ |$\gamma = 0.2$ |$\gamma = 0.3$ |$\gamma = 0.4$ |
|---------------------|---------------|---------------|---------------|---------------|
| embedding_size = 4  |     0.    |    0.     |    0.     |         | 
| embedding_size = 8  |     0.    |    0.6096     |    0.6059     |         | 
| embedding_size = 12 |     0.    |    0.6147     |    0.6151     |    0.     | 
| embedding_size = 16 |     0.    |    0.6147     |    0.6087    |    0.     | 
| embedding_size = 20 |     0.    |    0.6090     |    0.6117     |    0.     | 






10%采样：

|         GAUC        |$\gamma = 0.1$ |$\gamma = 0.2$ |$\gamma = 0.3$ |
|---------------------|---------------|---------------|---------------|
| embedding_size = 4  |      0.   |   0.      |   0.      | 
| embedding_size = 8  |      0.   |   0.5996      |   0.      | 
| embedding_size = 12 |      0.   |   0.      |   0.      | 
| embedding_size = 16 |      0.   |   0.      |   0.      | 
